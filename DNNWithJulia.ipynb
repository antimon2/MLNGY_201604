{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Julia の紹介2<br><small>Julia で Deep Learning</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-size:150%;line-height:150%\">2016/04/16 機械学習 名古屋 第3回勉強会<br>後藤 俊介 ( @antimon2 )</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 自己紹介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 名前：後藤 俊介\n",
    "+ 所属コミュニティ：**機械学習名古屋**（主催者の1人）、Python東海、Ruby東海\n",
    "+ 言語：**Julia**, Python, Ruby, JavaScript, …\n",
    "+ twitter: [@antimon2](https://twitter.com/antimon2 \"あんちもん2(@antimon2)さん | Twitter\")\n",
    "+ Facebook: [antimon2](https://www.facebook.com/antimon2 \"後藤 俊介\")\n",
    "+ GitHub: [antimon2](https://github.com/antimon2/ \"antimon2 (GOTOH Shunsuke)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "↑今日もこの **Julia** の話。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Julia とは？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "※ 前回発表資料の流用（コピペ＋一部修正）です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [The Julia Language](http://julialang.org/)\n",
    "- 2015/10/04 に [v0.4.0 がリリース](http://julialang.org/blog/2015/10/julia-0.4-release/)（2016/04/16 現在の最新は v0.4.5）\n",
    "- Python/Ruby/R 等の「いいとこどり」言語（詳細後述）\n",
    "- 動作が速い！（LLVM JIT コンパイル）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Julia の特長"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> + Rのように中身がぐちゃぐちゃでなく、\n",
    "+ Rubyのように遅くなく、\n",
    "+ Lispのように原始的またはエレファントでなく、\n",
    "+ Prologのように変態的なところはなく、\n",
    "+ Javaのように硬すぎることはなく、\n",
    "+ Haskellのように抽象的すぎない\n",
    "> \n",
    "> ほどよい言語である\n",
    "\n",
    "引用：http://www.slideshare.net/Nikoriks/julia-28059489"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Julia の目指すもの：\n",
    "\n",
    "+ C のように高速だけど、  \n",
    "  Ruby のような動的型付言語である\n",
    "+ Lisp のように同じ文法で書けるマクロがあって、しかも  \n",
    "  Matlab のような直感的な数式表現もできる\n",
    "+ Python のように総合的なプログラミングができて、  \n",
    "  R のように統計処理も得意で、  \n",
    "  Perl のように文字列処理もできて、  \n",
    "  Matlab のように線形代数もできて、  \n",
    "  shell のように複数のプログラムを組み合わせることもできる\n",
    "+ 超初心者にも習得は簡単で、  \n",
    "  超上級者の満足にも応えられる\n",
    "+ インタラクティブにも動作して、コンパイルもできる\n",
    "\n",
    "（[Why We Created Julia](http://julialang.org/blog/2012/02/why-we-created-julia/) から抜粋・私訳）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep Learning への適用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia の Deep Learning 用パッケージの紹介。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "※ この記事は Julia v0.4.5 を基準としています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ [Mocha](https://github.com/pluskid/Mocha.jl)（C++ 用の [Caffe](http://caffe.berkeleyvision.org/) にインスパイアされて生まれたフレームワーク。互換性・可搬性・速度がウリ）\n",
    "+ [MXNet](https://github.com/dmlc/MXNet.jl)（2015/10 に出たばかりの新しいフレームワーク。軽量・効率性・柔軟性がウリ）\n",
    "+ [PyCall](https://github.com/stevengj/PyCall.jl)（Julia から Python を呼び出すパッケージ。Python にインストール済の機械学習パッケージ（例：TensorFlow）を利用可能）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mocha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ すべて Julia で書かれた DeepLearning フレームワーク。\n",
    "+ 考え方、記述方法等、色々 Caffe から引き継いでいる。\n",
    "+ 扱えるデータ形式等、他のフレームワークとの互換性も持っている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Mocha のインストール"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（Julia コンソールから↓）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pkg.add(\"Mocha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "※ `Blosc`, `HDF5`, `JLD` 等いくつかの依存パッケージも同時に追加される。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring Mocha...\n",
      " * CUDA       disabled by default\n",
      " * Native Ext disabled by default\n",
      "Mocha configured, continue loading module...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition info(Any...) in module Base at util.jl:334 overwritten in module Logging at /Users/antimon2/.julia/v0.4/Logging/src/Logging.jl:61.\n",
      "WARNING: Method definition warn(Any...) in module Base at util.jl:364 overwritten in module Logging at /Users/antimon2/.julia/v0.4/Logging/src/Logging.jl:61.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DefaultBackend = Mocha.CPUBackend\n"
     ]
    }
   ],
   "source": [
    "using Mocha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ../MNIST_data/train.hdf5\n",
      "\n",
      "test: ../MNIST_data/test.hdf5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(\"train: \", open(readall, \"train.txt\"))\n",
    "println(\"test: \", open(readall, \"test.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mocha.AsyncHDF5DataLayer(train-data)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_layer  = AsyncHDF5DataLayer(name=\"train-data\", source=\"train.txt\", batch_size=64, shuffle=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mocha.SoftmaxLossLayer(loss)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1_layer = InnerProductLayer(name=\"h1\", output_dim=128, neuron=Neurons.ReLU(), bottoms=[:data], tops=[:h1])\n",
    "h2_layer = InnerProductLayer(name=\"h2\", output_dim=64, neuron=Neurons.ReLU(), bottoms=[:h1], tops=[:h2])\n",
    "output_layer = InnerProductLayer(name=\"y\", output_dim=10, bottoms=[:h2], tops=[:y])\n",
    "loss_layer = SoftmaxLossLayer(name=\"loss\", bottoms=[:y,:label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "backend = DefaultBackend()\n",
    "init(backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11- 4 21:00:08:INFO:root:Constructing net MNIST-train on Mocha.CPUBackend...\n",
      "11- 4 21:00:08:INFO:root:Topological sorting 5 layers...\n",
      "11- 4 21:00:08:INFO:root:Setup layers...\n",
      "11- 4 21:00:09:INFO:root:Network constructed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "************************************************************\n",
       "          NAME: MNIST-train\n",
       "       BACKEND: Mocha.CPUBackend\n",
       "  ARCHITECTURE: 5 layers\n",
       "............................................................\n",
       " *** Mocha.AsyncHDF5DataLayer(train-data)\n",
       "    Outputs ---------------------------\n",
       "          data: Blob(28 x 28 x 1 x 64)\n",
       "         label: Blob(1 x 64)\n",
       "............................................................\n",
       " *** Mocha.InnerProductLayer(h1)\n",
       "    Inputs ----------------------------\n",
       "          data: Blob(28 x 28 x 1 x 64)\n",
       "    Outputs ---------------------------\n",
       "            h1: Blob(128 x 64)\n",
       "............................................................\n",
       " *** Mocha.InnerProductLayer(h2)\n",
       "    Inputs ----------------------------\n",
       "            h1: Blob(128 x 64)\n",
       "    Outputs ---------------------------\n",
       "            h2: Blob(64 x 64)\n",
       "............................................................\n",
       " *** Mocha.InnerProductLayer(y)\n",
       "    Inputs ----------------------------\n",
       "            h2: Blob(64 x 64)\n",
       "    Outputs ---------------------------\n",
       "             y: Blob(10 x 64)\n",
       "............................................................\n",
       " *** Mocha.SoftmaxLossLayer(loss)\n",
       "    Inputs ----------------------------\n",
       "             y: Blob(10 x 64)\n",
       "         label: Blob(1 x 64)\n",
       "************************************************************\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_layers = [h1_layer, h2_layer, output_layer]\n",
    "net = Net(\"MNIST-train\", backend, [data_layer, common_layers..., loss_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mocha.Solver{Mocha.SGD}(Mocha.SGD(),Dict{Symbol,Any}(:regu_coef=>0.0005,:load_from=>\"\",:lr_policy=>Mocha.LRPolicy.Inv(0.01,0.0001,0.75),:mom_policy=>Mocha.MomPolicy.Fixed(0.9),:max_iter=>10000),Mocha.CoffeeLounge(\"\",1,:merge,Dict{AbstractString,Dict{Int64,AbstractFloat}}(),Mocha.CoffeeBreak[],false,13366444472,4670276080))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = SGD()\n",
    "params = make_solver_parameters(method, max_iter=10000, regu_coef=0.0005,\n",
    "                                mom_policy=MomPolicy.Fixed(0.9),\n",
    "                                lr_policy=LRPolicy.Inv(0.01, 0.0001, 0.75))\n",
    "solver = Solver(method, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":merge"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup_coffee_lounge(solver, every_n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Mocha.CoffeeBreak,1}:\n",
       " Mocha.CoffeeBreak(Mocha.TrainingSummary(Any[:iter,:obj_val]),100,0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# report training progress every 100 iterations\n",
    "add_coffee_break(solver, TrainingSummary(), every_n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11- 4 21:03:41:INFO:root:Constructing net MNIST-test on Mocha.CPUBackend...\n",
      "11- 4 21:03:41:INFO:root:Topological sorting 5 layers...\n",
      "11- 4 21:03:41:INFO:root:Setup layers...\n",
      "11- 4 21:03:41:DEBUG:root:InnerProductLayer(h1): sharing weights and bias\n",
      "11- 4 21:03:41:DEBUG:root:InnerProductLayer(h2): sharing weights and bias\n",
      "11- 4 21:03:41:DEBUG:root:InnerProductLayer(y): sharing weights and bias\n",
      "11- 4 21:03:41:INFO:root:Network constructed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Array{Mocha.CoffeeBreak,1}:\n",
       " Mocha.CoffeeBreak(Mocha.TrainingSummary(Any[:iter,:obj_val]),100,0)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       " Mocha.CoffeeBreak(Mocha.ValidationPerformance(************************************************************\n",
       "          NAME: MNIST-test\n",
       "       BACKEND: Mocha.CPUBackend\n",
       "  ARCHITECTURE: 5 layers\n",
       "............................................................\n",
       " *** Mocha.HDF5DataLayer(test-data)\n",
       "    Outputs ---------------------------\n",
       "          data: Blob(28 x 28 x 1 x 100)\n",
       "         label: Blob(1 x 100)\n",
       "............................................................\n",
       " *** Mocha.InnerProductLayer(h1)\n",
       "    Inputs ----------------------------\n",
       "          data: Blob(28 x 28 x 1 x 100)\n",
       "    Outputs ---------------------------\n",
       "            h1: Blob(128 x 100)\n",
       "............................................................\n",
       " *** Mocha.InnerProductLayer(h2)\n",
       "    Inputs ----------------------------\n",
       "            h1: Blob(128 x 100)\n",
       "    Outputs ---------------------------\n",
       "            h2: Blob(64 x 100)\n",
       "............................................................\n",
       " *** Mocha.InnerProductLayer(y)\n",
       "    Inputs ----------------------------\n",
       "            h2: Blob(64 x 100)\n",
       "    Outputs ---------------------------\n",
       "             y: Blob(10 x 100)\n",
       "............................................................\n",
       " *** Mocha.AccuracyLayer(test-accuracy)\n",
       "    Inputs ----------------------------\n",
       "             y: Blob(10 x 100)\n",
       "         label: Blob(1 x 100)\n",
       "************************************************************\n",
       ",Function[]),1000,0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show performance on test data every 1000 iterations\n",
    "data_layer_test = HDF5DataLayer(name=\"test-data\", source=\"test.txt\", batch_size=100)\n",
    "acc_layer = AccuracyLayer(name=\"test-accuracy\", bottoms=[:y, :label])\n",
    "test_net = Net(\"MNIST-test\", backend, [data_layer_test, common_layers..., acc_layer])\n",
    "add_coffee_break(solver, ValidationPerformance(test_net), every_n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11- 4 21:03:54:DEBUG:root:#DEBUG Checking network topology for back-propagation\n",
      "11- 4 21:03:54:DEBUG:root:Init network MNIST-train\n",
      "11- 4 21:03:54:DEBUG:root:Init parameter weight for layer h1\n",
      "11- 4 21:03:54:DEBUG:root:Init parameter bias for layer h1\n",
      "11- 4 21:03:54:DEBUG:root:Init parameter weight for layer h2\n",
      "11- 4 21:03:54:DEBUG:root:Init parameter bias for layer h2\n",
      "11- 4 21:03:54:DEBUG:root:Init parameter weight for layer y\n",
      "11- 4 21:03:54:DEBUG:root:Init parameter bias for layer y\n",
      "11- 4 21:03:56:DEBUG:root:#DEBUG Initializing coffee breaks\n",
      "11- 4 21:03:56:DEBUG:root:Init network MNIST-test\n",
      "11- 4 21:03:56:INFO:root: TRAIN iter=000000 obj_val=2.34824681\n",
      "11- 4 21:03:57:INFO:root:\n",
      "11- 4 21:03:57:INFO:root:## Performance on Validation Set after 0 iterations\n",
      "11- 4 21:03:57:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:03:57:INFO:root:  Accuracy (avg over 10000) = 9.8000%\n",
      "11- 4 21:03:57:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:03:57:INFO:root:\n",
      "11- 4 21:03:57:DEBUG:root:#DEBUG Entering solver loop\n",
      "11- 4 21:03:57:INFO:root: TRAIN iter=000100 obj_val=0.72044843\n",
      "11- 4 21:03:57:INFO:root: TRAIN iter=000200 obj_val=0.38439170\n",
      "11- 4 21:03:57:INFO:root: TRAIN iter=000300 obj_val=0.38048720\n",
      "11- 4 21:03:58:INFO:root: TRAIN iter=000400 obj_val=0.30124348\n",
      "11- 4 21:03:58:INFO:root: TRAIN iter=000500 obj_val=0.31457934\n",
      "11- 4 21:03:58:INFO:root: TRAIN iter=000600 obj_val=0.26442590\n",
      "11- 4 21:03:58:INFO:root: TRAIN iter=000700 obj_val=0.13717851\n",
      "11- 4 21:03:58:INFO:root: TRAIN iter=000800 obj_val=0.43488461\n",
      "11- 4 21:03:59:INFO:root: TRAIN iter=000900 obj_val=0.22953948\n",
      "11- 4 21:03:59:INFO:root: TRAIN iter=001000 obj_val=0.17241921\n",
      "11- 4 21:03:59:INFO:root:\n",
      "11- 4 21:03:59:INFO:root:## Performance on Validation Set after 1000 iterations\n",
      "11- 4 21:03:59:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:03:59:INFO:root:  Accuracy (avg over 10000) = 93.6900%\n",
      "11- 4 21:03:59:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:03:59:INFO:root:\n",
      "11- 4 21:03:59:INFO:root: TRAIN iter=001100 obj_val=0.16682526\n",
      "11- 4 21:04:00:INFO:root: TRAIN iter=001200 obj_val=0.16624433\n",
      "11- 4 21:04:00:INFO:root: TRAIN iter=001300 obj_val=0.15135027\n",
      "11- 4 21:04:00:INFO:root: TRAIN iter=001400 obj_val=0.16512160\n",
      "11- 4 21:04:01:INFO:root: TRAIN iter=001500 obj_val=0.37728232\n",
      "11- 4 21:04:01:INFO:root: TRAIN iter=001600 obj_val=0.13196075\n",
      "11- 4 21:04:01:INFO:root: TRAIN iter=001700 obj_val=0.16036817\n",
      "11- 4 21:04:01:INFO:root: TRAIN iter=001800 obj_val=0.13139708\n",
      "11- 4 21:04:02:INFO:root: TRAIN iter=001900 obj_val=0.08048051\n",
      "11- 4 21:04:02:INFO:root: TRAIN iter=002000 obj_val=0.21700971\n",
      "11- 4 21:04:02:INFO:root:\n",
      "11- 4 21:04:02:INFO:root:## Performance on Validation Set after 2000 iterations\n",
      "11- 4 21:04:02:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:04:02:INFO:root:  Accuracy (avg over 10000) = 95.7400%\n",
      "11- 4 21:04:02:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:04:02:INFO:root:\n",
      "11- 4 21:04:02:INFO:root: TRAIN iter=002100 obj_val=0.17794394\n",
      "11- 4 21:04:02:INFO:root: TRAIN iter=002200 obj_val=0.17865175\n",
      "11- 4 21:04:03:INFO:root: TRAIN iter=002300 obj_val=0.13859107\n",
      "11- 4 21:04:03:INFO:root: TRAIN iter=002400 obj_val=0.07124933\n",
      "11- 4 21:04:03:INFO:root: TRAIN iter=002500 obj_val=0.14039499\n",
      "11- 4 21:04:04:INFO:root: TRAIN iter=002600 obj_val=0.19957620\n",
      "11- 4 21:04:04:INFO:root: TRAIN iter=002700 obj_val=0.21071512\n",
      "11- 4 21:04:04:INFO:root: TRAIN iter=002800 obj_val=0.16656896\n",
      "11- 4 21:04:04:INFO:root: TRAIN iter=002900 obj_val=0.07055696\n",
      "11- 4 21:04:05:INFO:root: TRAIN iter=003000 obj_val=0.08008964\n",
      "11- 4 21:04:05:INFO:root:\n",
      "11- 4 21:04:05:INFO:root:## Performance on Validation Set after 3000 iterations\n",
      "11- 4 21:04:05:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:04:05:INFO:root:  Accuracy (avg over 10000) = 96.3000%\n",
      "11- 4 21:04:05:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:04:05:INFO:root:\n",
      "11- 4 21:04:05:INFO:root: TRAIN iter=003100 obj_val=0.14735544\n",
      "11- 4 21:04:05:INFO:root: TRAIN iter=003200 obj_val=0.04965867\n",
      "11- 4 21:04:05:INFO:root: TRAIN iter=003300 obj_val=0.13227178\n",
      "11- 4 21:04:06:INFO:root: TRAIN iter=003400 obj_val=0.21736640\n",
      "11- 4 21:04:06:INFO:root: TRAIN iter=003500 obj_val=0.20425765\n",
      "11- 4 21:04:06:INFO:root: TRAIN iter=003600 obj_val=0.04673606\n",
      "11- 4 21:04:06:INFO:root: TRAIN iter=003700 obj_val=0.22606722\n",
      "11- 4 21:04:07:INFO:root: TRAIN iter=003800 obj_val=0.13374050\n",
      "11- 4 21:04:07:INFO:root: TRAIN iter=003900 obj_val=0.10839496\n",
      "11- 4 21:04:07:INFO:root: TRAIN iter=004000 obj_val=0.06521919\n",
      "11- 4 21:04:07:INFO:root:\n",
      "11- 4 21:04:07:INFO:root:## Performance on Validation Set after 4000 iterations\n",
      "11- 4 21:04:07:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:04:07:INFO:root:  Accuracy (avg over 10000) = 96.9200%\n",
      "11- 4 21:04:07:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:04:07:INFO:root:\n",
      "11- 4 21:04:08:INFO:root: TRAIN iter=004100 obj_val=0.05701694\n",
      "11- 4 21:04:08:INFO:root: TRAIN iter=004200 obj_val=0.09259994\n",
      "11- 4 21:04:08:INFO:root: TRAIN iter=004300 obj_val=0.14057802\n",
      "11- 4 21:04:08:INFO:root: TRAIN iter=004400 obj_val=0.03744325\n",
      "11- 4 21:04:09:INFO:root: TRAIN iter=004500 obj_val=0.04957540\n",
      "11- 4 21:04:09:INFO:root: TRAIN iter=004600 obj_val=0.03862289\n",
      "11- 4 21:04:09:INFO:root: TRAIN iter=004700 obj_val=0.09002122\n",
      "11- 4 21:04:10:INFO:root: TRAIN iter=004800 obj_val=0.13155897\n",
      "11- 4 21:04:10:INFO:root: TRAIN iter=004900 obj_val=0.03018349\n",
      "11- 4 21:04:10:INFO:root: TRAIN iter=005000 obj_val=0.06427309\n",
      "11- 4 21:04:10:INFO:root:\n",
      "11- 4 21:04:10:INFO:root:## Performance on Validation Set after 5000 iterations\n",
      "11- 4 21:04:10:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:04:10:INFO:root:  Accuracy (avg over 10000) = 97.3000%\n",
      "11- 4 21:04:10:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:04:10:INFO:root:\n",
      "11- 4 21:04:10:INFO:root: TRAIN iter=005100 obj_val=0.09457170\n",
      "11- 4 21:04:11:INFO:root: TRAIN iter=005200 obj_val=0.19651015\n",
      "11- 4 21:04:11:INFO:root: TRAIN iter=005300 obj_val=0.04328072\n",
      "11- 4 21:04:11:INFO:root: TRAIN iter=005400 obj_val=0.16651781\n",
      "11- 4 21:04:11:INFO:root: TRAIN iter=005500 obj_val=0.13126096\n",
      "11- 4 21:04:11:INFO:root: TRAIN iter=005600 obj_val=0.03568171\n",
      "11- 4 21:04:12:INFO:root: TRAIN iter=005700 obj_val=0.06573341\n",
      "11- 4 21:04:12:INFO:root: TRAIN iter=005800 obj_val=0.08173248\n",
      "11- 4 21:04:12:INFO:root: TRAIN iter=005900 obj_val=0.04529405\n",
      "11- 4 21:04:13:INFO:root: TRAIN iter=006000 obj_val=0.19562599\n",
      "11- 4 21:04:13:INFO:root:\n",
      "11- 4 21:04:13:INFO:root:## Performance on Validation Set after 6000 iterations\n",
      "11- 4 21:04:13:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:04:13:INFO:root:  Accuracy (avg over 10000) = 97.5000%\n",
      "11- 4 21:04:13:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:04:13:INFO:root:\n",
      "11- 4 21:04:13:INFO:root: TRAIN iter=006100 obj_val=0.07675086\n",
      "11- 4 21:04:13:INFO:root: TRAIN iter=006200 obj_val=0.02949132\n",
      "11- 4 21:04:14:INFO:root: TRAIN iter=006300 obj_val=0.03736485\n",
      "11- 4 21:04:14:INFO:root: TRAIN iter=006400 obj_val=0.05456216\n",
      "11- 4 21:04:14:INFO:root: TRAIN iter=006500 obj_val=0.13938016\n",
      "11- 4 21:04:14:INFO:root: TRAIN iter=006600 obj_val=0.06659289\n",
      "11- 4 21:04:15:INFO:root: TRAIN iter=006700 obj_val=0.04390205\n",
      "11- 4 21:04:15:INFO:root: TRAIN iter=006800 obj_val=0.03863468\n",
      "11- 4 21:04:15:INFO:root: TRAIN iter=006900 obj_val=0.05896043\n",
      "11- 4 21:04:15:INFO:root: TRAIN iter=007000 obj_val=0.02534590\n",
      "11- 4 21:04:16:INFO:root:\n",
      "11- 4 21:04:16:INFO:root:## Performance on Validation Set after 7000 iterations\n",
      "11- 4 21:04:16:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:04:16:INFO:root:  Accuracy (avg over 10000) = 97.4400%\n",
      "11- 4 21:04:16:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:04:16:INFO:root:\n",
      "11- 4 21:04:16:INFO:root: TRAIN iter=007100 obj_val=0.13920489\n",
      "11- 4 21:04:16:INFO:root: TRAIN iter=007200 obj_val=0.09845447\n",
      "11- 4 21:04:16:INFO:root: TRAIN iter=007300 obj_val=0.11148296\n",
      "11- 4 21:04:16:INFO:root: TRAIN iter=007400 obj_val=0.04689638\n",
      "11- 4 21:04:17:INFO:root: TRAIN iter=007500 obj_val=0.01518950\n",
      "11- 4 21:04:17:INFO:root: TRAIN iter=007600 obj_val=0.05005367\n",
      "11- 4 21:04:17:INFO:root: TRAIN iter=007700 obj_val=0.01336644\n",
      "11- 4 21:04:17:INFO:root: TRAIN iter=007800 obj_val=0.08371232\n",
      "11- 4 21:04:18:INFO:root: TRAIN iter=007900 obj_val=0.14074361\n",
      "11- 4 21:04:18:INFO:root: TRAIN iter=008000 obj_val=0.03779318\n",
      "11- 4 21:04:18:INFO:root:\n",
      "11- 4 21:04:18:INFO:root:## Performance on Validation Set after 8000 iterations\n",
      "11- 4 21:04:18:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:04:18:INFO:root:  Accuracy (avg over 10000) = 97.6600%\n",
      "11- 4 21:04:18:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:04:18:INFO:root:\n",
      "11- 4 21:04:18:INFO:root: TRAIN iter=008100 obj_val=0.06972453\n",
      "11- 4 21:04:19:INFO:root: TRAIN iter=008200 obj_val=0.02979052\n",
      "11- 4 21:04:19:INFO:root: TRAIN iter=008300 obj_val=0.12288050\n",
      "11- 4 21:04:19:INFO:root: TRAIN iter=008400 obj_val=0.05602855\n",
      "11- 4 21:04:19:INFO:root: TRAIN iter=008500 obj_val=0.01988741\n",
      "11- 4 21:04:20:INFO:root: TRAIN iter=008600 obj_val=0.03459808\n",
      "11- 4 21:04:20:INFO:root: TRAIN iter=008700 obj_val=0.02490192\n",
      "11- 4 21:04:20:INFO:root: TRAIN iter=008800 obj_val=0.05417839\n",
      "11- 4 21:04:20:INFO:root: TRAIN iter=008900 obj_val=0.10222290\n",
      "11- 4 21:04:21:INFO:root: TRAIN iter=009000 obj_val=0.09431160\n",
      "11- 4 21:04:21:INFO:root:\n",
      "11- 4 21:04:21:INFO:root:## Performance on Validation Set after 9000 iterations\n",
      "11- 4 21:04:21:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:04:21:INFO:root:  Accuracy (avg over 10000) = 97.5800%\n",
      "11- 4 21:04:21:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:04:21:INFO:root:\n",
      "11- 4 21:04:21:INFO:root: TRAIN iter=009100 obj_val=0.01482162\n",
      "11- 4 21:04:21:INFO:root: TRAIN iter=009200 obj_val=0.00954679\n",
      "11- 4 21:04:21:INFO:root: TRAIN iter=009300 obj_val=0.02515488\n",
      "11- 4 21:04:22:INFO:root: TRAIN iter=009400 obj_val=0.06189635\n",
      "11- 4 21:04:22:INFO:root: TRAIN iter=009500 obj_val=0.05028667\n",
      "11- 4 21:04:22:INFO:root: TRAIN iter=009600 obj_val=0.06645393\n",
      "11- 4 21:04:22:INFO:root: TRAIN iter=009700 obj_val=0.02867734\n",
      "11- 4 21:04:23:INFO:root: TRAIN iter=009800 obj_val=0.07310568\n",
      "11- 4 21:04:23:INFO:root: TRAIN iter=009900 obj_val=0.00971673\n",
      "11- 4 21:04:23:INFO:root: TRAIN iter=010000 obj_val=0.03114462\n",
      "11- 4 21:04:23:INFO:root:\n",
      "11- 4 21:04:23:INFO:root:## Performance on Validation Set after 10000 iterations\n",
      "11- 4 21:04:23:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:04:23:INFO:root:  Accuracy (avg over 10000) = 97.7100%\n",
      "11- 4 21:04:23:INFO:root:---------------------------------------------------------\n",
      "11- 4 21:04:23:INFO:root:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Void,1},1}:\n",
       " [nothing,nothing]\n",
       " [nothing,nothing]\n",
       " [nothing,nothing]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve(solver, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11- 4 21:04:45:DEBUG:root:Destroying network MNIST-train\n",
      "11- 4 21:04:45:INFO:root:AsyncHDF5DataLayer: Stopping IO task...\n",
      "11- 4 21:04:45:INFO:root:AsyncHDF5DataLayer: IO Task reaching the end...\n",
      "11- 4 21:04:45:DEBUG:root:Destroying network MNIST-test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{AbstractString,Array{Mocha.AbstractParameter,1}} with 0 entries"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destroy(net)\n",
    "destroy(test_net)\n",
    "shutdown(backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MXNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Julia, Python, R, Go, JavaScript などに対応した DeepLearning フレームワーク。\n",
    "+ 記述の簡潔さと、（それに伴う）「効率」と「柔軟性」の両立。\n",
    "+ 処理のコア部分は C(C++) で記述されている（それにより軽量性と多言語対応を実現している）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### MXNet のインストール"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（Julia コンソールから↓）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pkg.add(\"MXNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "※ ダイナミックリンクライブラリ libmxnet.so のビルドまでやってくれる。  \n",
    "※ OpenCV の利用、CUDNN 等の利用に際しては、別途それらを有効にして libmxnet.so をビルドし、それを利用するよう `MXNet.jl` を再セットアップする必要あり。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using MXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MXNet.mx.SymbolicNode(MXNet.mx.MX_SymbolHandle(Ptr{Void} @0x00007fd615314af0))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3LP ネットワーク構築\n",
    "mlp = @mx.chain mx.Variable(:data)             =>\n",
    "  mx.FullyConnected(name=:fc1, num_hidden=128) =>\n",
    "  mx.Activation(name=:relu1, act_type=:relu)   =>\n",
    "  mx.FullyConnected(name=:fc2, num_hidden=64)  =>\n",
    "  mx.Activation(name=:relu2, act_type=:relu)   =>\n",
    "  mx.FullyConnected(name=:fc3, num_hidden=10)  =>\n",
    "  mx.SoftmaxOutput(name=:softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MXNet.mx.MXDataProvider(MXNet.mx.MX_DataIterHandle(Ptr{Void} @0x00007fd6153872f0),Tuple{Symbol,Tuple}[(:data,(784,100))],Tuple{Symbol,Tuple}[(:softmax_label,(100,))],100,true,true)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データ取得（データプロバイダ生成）\n",
    "batch_size = 100\n",
    "# include(Pkg.dir(\"MXNet\", \"examples\", \"mnist\", \"mnist-data.jl\"))\n",
    "# train_provider, eval_provider = get_mnist_providers(batch_size)\n",
    "data_name = :data\n",
    "label_name = :softmax_label\n",
    "flat=true\n",
    "train_provider = mx.MNISTProvider(image=\"../MNIST_data/train-images-idx3-ubyte\",\n",
    "                                  label=\"../MNIST_data/train-labels-idx1-ubyte\",\n",
    "                                  data_name=data_name, label_name=label_name,\n",
    "                                  batch_size=batch_size, shuffle=true, flat=flat, silent=true)\n",
    "eval_provider = mx.MNISTProvider(image=\"../MNIST_data/t10k-images-idx3-ubyte\",\n",
    "                                 label=\"../MNIST_data/t10k-labels-idx1-ubyte\",\n",
    "                                 data_name=data_name, label_name=label_name,\n",
    "                                 batch_size=batch_size, shuffle=false, flat=flat, silent=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11- 4 21:31:42:INFO:root:Start training on [CPU0]\n",
      "11- 4 21:31:42:INFO:root:Initializing parameters...\n",
      "11- 4 21:31:43:INFO:root:Creating KVStore...\n",
      "11- 4 21:31:43:INFO:root:Start training...\n",
      "11- 4 21:31:45:INFO:root:== Epoch 001 ==========\n",
      "11- 4 21:31:45:INFO:root:## Training summary\n",
      "11- 4 21:31:45:INFO:root:          accuracy = 0.7548\n",
      "11- 4 21:31:45:INFO:root:              time = 1.4513 seconds\n",
      "11- 4 21:31:45:INFO:root:## Validation summary\n",
      "11- 4 21:31:45:INFO:root:          accuracy = 0.9498\n",
      "11- 4 21:31:46:INFO:root:== Epoch 002 ==========\n",
      "11- 4 21:31:46:INFO:root:## Training summary\n",
      "11- 4 21:31:46:INFO:root:          accuracy = 0.9575\n",
      "11- 4 21:31:46:INFO:root:              time = 0.9477 seconds\n",
      "11- 4 21:31:46:INFO:root:## Validation summary\n",
      "11- 4 21:31:46:INFO:root:          accuracy = 0.9678\n",
      "11- 4 21:31:47:INFO:root:== Epoch 003 ==========\n",
      "11- 4 21:31:47:INFO:root:## Training summary\n",
      "11- 4 21:31:47:INFO:root:          accuracy = 0.9700\n",
      "11- 4 21:31:47:INFO:root:              time = 0.9656 seconds\n",
      "11- 4 21:31:47:INFO:root:## Validation summary\n",
      "11- 4 21:31:47:INFO:root:          accuracy = 0.9689\n",
      "11- 4 21:31:49:INFO:root:== Epoch 004 ==========\n",
      "11- 4 21:31:49:INFO:root:## Training summary\n",
      "11- 4 21:31:49:INFO:root:          accuracy = 0.9760\n",
      "11- 4 21:31:49:INFO:root:              time = 1.5287 seconds\n",
      "11- 4 21:31:49:INFO:root:## Validation summary\n",
      "11- 4 21:31:49:INFO:root:          accuracy = 0.9694\n",
      "11- 4 21:31:50:INFO:root:== Epoch 005 ==========\n",
      "11- 4 21:31:50:INFO:root:## Training summary\n",
      "11- 4 21:31:50:INFO:root:          accuracy = 0.9811\n",
      "11- 4 21:31:50:INFO:root:              time = 1.0568 seconds\n",
      "11- 4 21:31:50:INFO:root:## Validation summary\n",
      "11- 4 21:31:50:INFO:root:          accuracy = 0.9750\n",
      "11- 4 21:31:51:INFO:root:== Epoch 006 ==========\n",
      "11- 4 21:31:51:INFO:root:## Training summary\n",
      "11- 4 21:31:51:INFO:root:          accuracy = 0.9840\n",
      "11- 4 21:31:51:INFO:root:              time = 0.9398 seconds\n",
      "11- 4 21:31:51:INFO:root:## Validation summary\n",
      "11- 4 21:31:51:INFO:root:          accuracy = 0.9721\n",
      "11- 4 21:31:52:INFO:root:== Epoch 007 ==========\n",
      "11- 4 21:31:52:INFO:root:## Training summary\n",
      "11- 4 21:31:52:INFO:root:          accuracy = 0.9854\n",
      "11- 4 21:31:52:INFO:root:              time = 0.9064 seconds\n",
      "11- 4 21:31:52:INFO:root:## Validation summary\n",
      "11- 4 21:31:52:INFO:root:          accuracy = 0.9757\n",
      "11- 4 21:31:53:INFO:root:== Epoch 008 ==========\n",
      "11- 4 21:31:53:INFO:root:## Training summary\n",
      "11- 4 21:31:53:INFO:root:          accuracy = 0.9862\n",
      "11- 4 21:31:53:INFO:root:              time = 1.3213 seconds\n",
      "11- 4 21:31:53:INFO:root:## Validation summary\n",
      "11- 4 21:31:53:INFO:root:          accuracy = 0.9716\n",
      "11- 4 21:31:54:INFO:root:== Epoch 009 ==========\n",
      "11- 4 21:31:54:INFO:root:## Training summary\n",
      "11- 4 21:31:54:INFO:root:          accuracy = 0.9879\n",
      "11- 4 21:31:54:INFO:root:              time = 0.9961 seconds\n",
      "11- 4 21:31:54:INFO:root:## Validation summary\n",
      "11- 4 21:31:54:INFO:root:          accuracy = 0.9761\n",
      "11- 4 21:31:55:INFO:root:== Epoch 010 ==========\n",
      "11- 4 21:31:55:INFO:root:## Training summary\n",
      "11- 4 21:31:55:INFO:root:          accuracy = 0.9884\n",
      "11- 4 21:31:55:INFO:root:              time = 1.0097 seconds\n",
      "11- 4 21:31:55:INFO:root:## Validation summary\n",
      "11- 4 21:31:55:INFO:root:          accuracy = 0.9726\n",
      "11- 4 21:31:57:INFO:root:== Epoch 011 ==========\n",
      "11- 4 21:31:57:INFO:root:## Training summary\n",
      "11- 4 21:31:57:INFO:root:          accuracy = 0.9890\n",
      "11- 4 21:31:57:INFO:root:              time = 1.3738 seconds\n",
      "11- 4 21:31:57:INFO:root:## Validation summary\n",
      "11- 4 21:31:57:INFO:root:          accuracy = 0.9755\n",
      "11- 4 21:31:58:INFO:root:== Epoch 012 ==========\n",
      "11- 4 21:31:58:INFO:root:## Training summary\n",
      "11- 4 21:31:58:INFO:root:          accuracy = 0.9895\n",
      "11- 4 21:31:58:INFO:root:              time = 1.0321 seconds\n",
      "11- 4 21:31:58:INFO:root:## Validation summary\n",
      "11- 4 21:31:58:INFO:root:          accuracy = 0.9791\n",
      "11- 4 21:31:59:INFO:root:== Epoch 013 ==========\n",
      "11- 4 21:31:59:INFO:root:## Training summary\n",
      "11- 4 21:31:59:INFO:root:          accuracy = 0.9901\n",
      "11- 4 21:31:59:INFO:root:              time = 0.9508 seconds\n",
      "11- 4 21:31:59:INFO:root:## Validation summary\n",
      "11- 4 21:31:59:INFO:root:          accuracy = 0.9772\n",
      "11- 4 21:32:00:INFO:root:== Epoch 014 ==========\n",
      "11- 4 21:32:00:INFO:root:## Training summary\n",
      "11- 4 21:32:00:INFO:root:          accuracy = 0.9917\n",
      "11- 4 21:32:00:INFO:root:              time = 0.9781 seconds\n",
      "11- 4 21:32:00:INFO:root:## Validation summary\n",
      "11- 4 21:32:00:INFO:root:          accuracy = 0.9772\n",
      "11- 4 21:32:01:INFO:root:== Epoch 015 ==========\n",
      "11- 4 21:32:01:INFO:root:## Training summary\n",
      "11- 4 21:32:01:INFO:root:          accuracy = 0.9910\n",
      "11- 4 21:32:01:INFO:root:              time = 0.9866 seconds\n",
      "11- 4 21:32:01:INFO:root:## Validation summary\n",
      "11- 4 21:32:01:INFO:root:          accuracy = 0.9772\n",
      "11- 4 21:32:02:INFO:root:== Epoch 016 ==========\n",
      "11- 4 21:32:02:INFO:root:## Training summary\n",
      "11- 4 21:32:02:INFO:root:          accuracy = 0.9925\n",
      "11- 4 21:32:02:INFO:root:              time = 0.9422 seconds\n",
      "11- 4 21:32:02:INFO:root:## Validation summary\n",
      "11- 4 21:32:02:INFO:root:          accuracy = 0.9774\n",
      "11- 4 21:32:03:INFO:root:== Epoch 017 ==========\n",
      "11- 4 21:32:03:INFO:root:## Training summary\n",
      "11- 4 21:32:03:INFO:root:          accuracy = 0.9929\n",
      "11- 4 21:32:03:INFO:root:              time = 0.9162 seconds\n",
      "11- 4 21:32:03:INFO:root:## Validation summary\n",
      "11- 4 21:32:03:INFO:root:          accuracy = 0.9762\n",
      "11- 4 21:32:04:INFO:root:== Epoch 018 ==========\n",
      "11- 4 21:32:04:INFO:root:## Training summary\n",
      "11- 4 21:32:04:INFO:root:          accuracy = 0.9925\n",
      "11- 4 21:32:04:INFO:root:              time = 0.9368 seconds\n",
      "11- 4 21:32:04:INFO:root:## Validation summary\n",
      "11- 4 21:32:04:INFO:root:          accuracy = 0.9800\n",
      "11- 4 21:32:05:INFO:root:== Epoch 019 ==========\n",
      "11- 4 21:32:05:INFO:root:## Training summary\n",
      "11- 4 21:32:05:INFO:root:          accuracy = 0.9940\n",
      "11- 4 21:32:05:INFO:root:              time = 0.9990 seconds\n",
      "11- 4 21:32:05:INFO:root:## Validation summary\n",
      "11- 4 21:32:05:INFO:root:          accuracy = 0.9804\n",
      "11- 4 21:32:06:INFO:root:== Epoch 020 ==========\n",
      "11- 4 21:32:06:INFO:root:## Training summary\n",
      "11- 4 21:32:06:INFO:root:          accuracy = 0.9940\n",
      "11- 4 21:32:06:INFO:root:              time = 1.2186 seconds\n",
      "11- 4 21:32:07:INFO:root:## Validation summary\n",
      "11- 4 21:32:07:INFO:root:          accuracy = 0.9799\n"
     ]
    }
   ],
   "source": [
    "# モデル構築・最適化\n",
    "\n",
    "# モデル setup\n",
    "model = mx.FeedForward(mlp, context=mx.cpu())\n",
    "\n",
    "# optimization algorithm\n",
    "optimizer = mx.SGD(lr=0.1, momentum=0.9)\n",
    "\n",
    "# fit parameters\n",
    "mx.fit(model, optimizer, train_provider, n_epoch=20, eval_data=eval_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10x10000 Array{Float32,2}:\n",
       " 1.06312e-10  5.80024e-13  2.965e-8     …  4.77526e-11  6.73342e-13\n",
       " 7.46479e-8   1.50914e-11  0.999939        3.83869e-11  9.10979e-16\n",
       " 5.39378e-9   1.0          2.33463e-5      2.85017e-13  2.81719e-13\n",
       " 4.7356e-7    4.01732e-8   8.18917e-10     5.87185e-10  3.66529e-16\n",
       " 8.03094e-10  2.75113e-16  3.04848e-6      3.1257e-14   2.58185e-13\n",
       " 2.61006e-9   8.06292e-16  5.892e-9     …  0.999999     1.2713e-11 \n",
       " 3.00019e-11  6.33867e-15  1.13649e-7      1.09904e-9   1.0        \n",
       " 0.999999     6.59821e-11  3.33885e-5      2.07988e-12  6.45652e-19\n",
       " 2.26256e-9   1.24287e-11  1.17842e-6      1.22676e-6   5.31528e-13\n",
       " 1.94323e-7   3.90443e-21  7.36552e-9      7.82996e-11  1.12308e-19"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 予測\n",
    "probs = mx.predict(model, eval_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on eval set: 97.99%\n"
     ]
    }
   ],
   "source": [
    "# 予測精度確認\n",
    "\n",
    "# collect all labels from eval data\n",
    "labels = Array[]\n",
    "for batch in eval_provider\n",
    "    push!(labels, copy(mx.get(eval_provider, batch, :softmax_label)))\n",
    "end\n",
    "labels = cat(1, labels...)\n",
    "\n",
    "# Now we use compute the accuracy\n",
    "correct = 0\n",
    "for i = 1:length(labels)\n",
    "    # labels are 0...9\n",
    "    if indmax(probs[:,i]) == labels[i]+1\n",
    "        correct += 1\n",
    "    end\n",
    "end\n",
    "accuracy = 100correct/length(labels)\n",
    "println(mx.format(\"Accuracy on eval set: {1:.2f}%\", accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PyCall + TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `PyCall` を利用すれば、Python にインストールした機械学習パッケージ等も利用可能（記述に独特のクセあり）。\n",
    "+ 例として、`TensorFlow` を利用してみる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### インストールと準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使用したいパッケージをインストールした Python の環境を環境変数に設定（pyenv や virtualenv で環境を分けている場合）\n",
    "ENV[\"PYTHON\"] = \"/path/to/user_home/.pyenv/versions/2.7.11/envs/TensorFlow/bin/python\"\n",
    "\n",
    "# PyCall 本体のインストール\n",
    "Pkg.add(\"PyCall\")\n",
    "\n",
    "# インストール済なら、依存ファイルを削除した上で再構築↓\n",
    "# rm(Pkg.dir(\"PyCall\",\"deps\",\"PYTHON\"))\n",
    "# Pkg.build(\"PyCall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using PyCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@pyimport tensorflow as tf\n",
    "# ↑Python の import 文と同様の書き方ができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject <tensorflow.examples.tutorials.mnist.input_data.DataSets object at 0x358d66150>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データ取得\n",
    "@pyimport tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "mnist = input_data.read_data_sets(\"../MNIST_data/\", one_hot=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Python で言う `from A.B import C` ということをしたい場合は、`@pyimport A.B.C as C` としなければならない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <tensorflow.python.framework.ops.Tensor object at 0x358d94510>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [nothing, 784])\n",
    "y_ = tf.placeholder(tf.float32, [nothing, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <tensorflow.python.framework.ops.Tensor object at 0x355058050>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3LP 構築\n",
    "W1 = tf.Variable(tf.random_normal(Int32[784, 128], mean=0.0, stddev=0.05))\n",
    "b1 = tf.Variable(tf.zeros(Int32[128]))\n",
    "W2 = tf.Variable(tf.random_normal(Int32[128, 64], mean=0.0, stddev=0.05))\n",
    "b2 = tf.Variable(tf.zeros(Int32[64]))\n",
    "W3 = tf.Variable(tf.random_normal(Int32[64, 10], mean=0.0, stddev=0.05))\n",
    "b3 = tf.Variable(tf.zeros(Int32[10]))\n",
    "\n",
    "h1 = tf.nn[:relu](tf.add(tf.matmul(x,  W1), b1))\n",
    "h2 = tf.nn[:relu](tf.add(tf.matmul(h1, W2), b2))\n",
    "y  = tf.nn[:softmax](tf.add(tf.matmul(h2, W3), b3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <tensorflow.python.framework.ops.Tensor object at 0x355066250>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy = tf.neg(tf.reduce_sum(tf.mul(y_, tf.log(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <tensorflow.python.framework.ops.Operation object at 0x358dd1490>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.train[:GradientDescentOptimizer](0.01)\n",
    "train_step = optimizer[:minimize](cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <tensorflow.python.framework.ops.Operation object at 0x358dd1c90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <tensorflow.python.framework.ops.Tensor object at 0x358dfae50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9571999907493591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 4\n",
      "I tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 4\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess[:run](tf_init)\n",
    "\n",
    "for i in 1:2000\n",
    "    batch_xs, batch_ys = mnist[:train][:next_batch](100)\n",
    "    sess[:run](train_step, feed_dict=Dict(x => batch_xs, y_ => batch_ys))\n",
    "end\n",
    "\n",
    "println(\"accuracy:$(sess[:run](accuracy, feed_dict=Dict(x => mnist[:test][:images], y_ => mnist[:test][:labels])))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 参考"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ [The Julia Language](http://julialang.org/)（本家サイト、英語）\n",
    "+ [Mocha](https://github.com/pluskid/Mocha.jl)\n",
    "+ [MXNet](https://github.com/dmlc/MXNet.jl)\n",
    "+ [PyCall](https://github.com/stevengj/PyCall.jl)\n",
    "+ [Julia - josephmisiti/awesome-machine-learning](https://github.com/josephmisiti/awesome-machine-learning#julia-general-purpose)（Julia の機械学習関連ライブラリのリンクまとめ。英語）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "ご清聴ありがとうございます。"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 0.4.5",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
