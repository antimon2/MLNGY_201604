{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Julia の紹介2<br><small>Julia で Deep Learning</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-size:150%;line-height:150%\">2016/04/16 機械学習 名古屋 第3回勉強会<br>後藤 俊介 ( @antimon2 )</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 自己紹介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 名前：後藤 俊介\n",
    "+ 所属コミュニティ：**機械学習名古屋**（主催者の1人）、Python東海、Ruby東海\n",
    "+ 言語：**Julia**, Python, Ruby, JavaScript, …\n",
    "+ twitter: [@antimon2](https://twitter.com/antimon2 \"あんちもん2(@antimon2)さん | Twitter\")\n",
    "+ Facebook: [antimon2](https://www.facebook.com/antimon2 \"後藤 俊介\")\n",
    "+ GitHub: [antimon2](https://github.com/antimon2/ \"antimon2 (GOTOH Shunsuke)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "↑今日もこの **Julia** の話。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Julia とは？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "※ 前回発表資料の流用（コピペ＋一部修正）です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [The Julia Language](http://julialang.org/)\n",
    "- 2015/10/04 に [v0.4.0 がリリース](http://julialang.org/blog/2015/10/julia-0.4-release/)（2016/04/16 現在の最新は v0.4.5）\n",
    "- Python/Ruby/R 等の「いいとこどり」言語（詳細後述）\n",
    "- 動作が速い！（LLVM JIT コンパイル）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Julia の特長"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> + Rのように中身がぐちゃぐちゃでなく、\n",
    "+ Rubyのように遅くなく、\n",
    "+ Lispのように原始的またはエレファントでなく、\n",
    "+ Prologのように変態的なところはなく、\n",
    "+ Javaのように硬すぎることはなく、\n",
    "+ Haskellのように抽象的すぎない\n",
    "> \n",
    "> ほどよい言語である\n",
    "\n",
    "引用：http://www.slideshare.net/Nikoriks/julia-28059489"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Julia の目指すもの：\n",
    "\n",
    "+ C のように高速だけど、  \n",
    "  Ruby のような動的型付言語である\n",
    "+ Lisp のように同じ文法で書けるマクロがあって、しかも  \n",
    "  Matlab のような直感的な数式表現もできる\n",
    "+ Python のように総合的なプログラミングができて、  \n",
    "  R のように統計処理も得意で、  \n",
    "  Perl のように文字列処理もできて、  \n",
    "  Matlab のように線形代数もできて、  \n",
    "  shell のように複数のプログラムを組み合わせることもできる\n",
    "+ 超初心者にも習得は簡単で、  \n",
    "  超上級者の満足にも応えられる\n",
    "+ インタラクティブにも動作して、コンパイルもできる\n",
    "\n",
    "（[Why We Created Julia](http://julialang.org/blog/2012/02/why-we-created-julia/) から抜粋・私訳）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep Learning への適用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia の Deep Learning 用パッケージの紹介。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "※ この記事は Julia v0.4.5 を基準としています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ [Mocha](https://github.com/pluskid/Mocha.jl)（C++ 用の [Caffe](http://caffe.berkeleyvision.org/) にインスパイアされて生まれたフレームワーク。互換性・可搬性・速度がウリ）\n",
    "+ [MXNet](https://github.com/dmlc/MXNet.jl)（2015/10 に出たばかりの新しいフレームワーク。軽量・効率性・柔軟性がウリ）\n",
    "+ [PyCall](https://github.com/stevengj/PyCall.jl)（Julia から Python を呼び出すパッケージ。Python にインストール済の機械学習パッケージ（例：TensorFlow）を利用可能）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mocha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ すべて Julia で書かれた DeepLearning フレームワーク。\n",
    "+ 考え方、記述方法等、色々 Caffe から引き継いでいる。\n",
    "+ 扱えるデータ形式等、他のフレームワークとの互換性も持っている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Mocha のインストール"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（Julia コンソールから↓）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pkg.add(\"Mocha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "※ `Blosc`, `HDF5`, `JLD` 等いくつかの依存パッケージも同時に追加される。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring Mocha...\n",
      " * CUDA       disabled by default\n",
      " * Native Ext disabled by default\n",
      "Mocha configured, continue loading module...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition info(Any...) in module Base at util.jl:334 overwritten in module Logging at /Users/antimon2/.julia/v0.4/Logging/src/Logging.jl:61.\n",
      "WARNING: Method definition warn(Any...) in module Base at util.jl:364 overwritten in module Logging at /Users/antimon2/.julia/v0.4/Logging/src/Logging.jl:61.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DefaultBackend = Mocha.CPUBackend\n"
     ]
    }
   ],
   "source": [
    "using Mocha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: MNIST_data/train.hdf5\n",
      "\n",
      "test: MNIST_data/test.hdf5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(\"train: \", open(readall, \"train.txt\"))\n",
    "println(\"test: \", open(readall, \"test.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mocha.AsyncHDF5DataLayer(train-data)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_layer  = AsyncHDF5DataLayer(name=\"train-data\", source=\"train.txt\", batch_size=64, shuffle=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mocha.SoftmaxLossLayer(loss)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1_layer = InnerProductLayer(name=\"h1\", output_dim=128, neuron=Neurons.ReLU(), bottoms=[:data], tops=[:h1])\n",
    "h2_layer = InnerProductLayer(name=\"h2\", output_dim=64, neuron=Neurons.ReLU(), bottoms=[:h1], tops=[:h2])\n",
    "output_layer = InnerProductLayer(name=\"y\", output_dim=10, bottoms=[:h2], tops=[:y])\n",
    "loss_layer = SoftmaxLossLayer(name=\"loss\", bottoms=[:y,:label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "backend = DefaultBackend()\n",
    "init(backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16- 4 00:17:21:INFO:root:Constructing net MNIST-train on Mocha.CPUBackend...\n",
      "16- 4 00:17:21:INFO:root:Topological sorting 5 layers...\n",
      "16- 4 00:17:21:INFO:root:Setup layers...\n",
      "16- 4 00:17:22:INFO:root:Network constructed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "************************************************************\n",
       "          NAME: MNIST-train\n",
       "       BACKEND: Mocha.CPUBackend\n",
       "  ARCHITECTURE: 5 layers\n",
       "............................................................\n",
       " *** Mocha.AsyncHDF5DataLayer(train-data)\n",
       "    Outputs ---------------------------\n",
       "          data: Blob(28 x 28 x 1 x 64)\n",
       "         label: Blob(1 x 64)\n",
       "............................................................\n",
       " *** Mocha.InnerProductLayer(h1)\n",
       "    Inputs ----------------------------\n",
       "          data: Blob(28 x 28 x 1 x 64)\n",
       "    Outputs ---------------------------\n",
       "            h1: Blob(128 x 64)\n",
       "............................................................\n",
       " *** Mocha.InnerProductLayer(h2)\n",
       "    Inputs ----------------------------\n",
       "            h1: Blob(128 x 64)\n",
       "    Outputs ---------------------------\n",
       "            h2: Blob(64 x 64)\n",
       "............................................................\n",
       " *** Mocha.InnerProductLayer(y)\n",
       "    Inputs ----------------------------\n",
       "            h2: Blob(64 x 64)\n",
       "    Outputs ---------------------------\n",
       "             y: Blob(10 x 64)\n",
       "............................................................\n",
       " *** Mocha.SoftmaxLossLayer(loss)\n",
       "    Inputs ----------------------------\n",
       "             y: Blob(10 x 64)\n",
       "         label: Blob(1 x 64)\n",
       "************************************************************\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_layers = [h1_layer, h2_layer, output_layer]\n",
    "net = Net(\"MNIST-train\", backend, [data_layer, common_layers..., loss_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mocha.Solver{Mocha.SGD}(Mocha.SGD(),Dict{Symbol,Any}(:regu_coef=>0.0005,:load_from=>\"\",:lr_policy=>Mocha.LRPolicy.Inv(0.01,0.0001,0.75),:mom_policy=>Mocha.MomPolicy.Fixed(0.9),:max_iter=>3000),Mocha.CoffeeLounge(\"\",1,:merge,Dict{AbstractString,Dict{Int64,AbstractFloat}}(),Mocha.CoffeeBreak[],false,4491540912,4480009008))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = SGD()\n",
    "params = make_solver_parameters(method, max_iter=3000, regu_coef=0.0005,\n",
    "                                mom_policy=MomPolicy.Fixed(0.9),\n",
    "                                lr_policy=LRPolicy.Inv(0.01, 0.0001, 0.75))\n",
    "solver = Solver(method, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":merge"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup_coffee_lounge(solver, every_n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Mocha.CoffeeBreak,1}:\n",
       " Mocha.CoffeeBreak(Mocha.TrainingSummary(Any[:iter,:obj_val]),1000,0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# report training progress every 1000 iterations\n",
    "add_coffee_break(solver, TrainingSummary(), every_n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16- 4 00:17:35:INFO:root:Constructing net MNIST-test on Mocha.CPUBackend...\n",
      "16- 4 00:17:35:INFO:root:Topological sorting 5 layers...\n",
      "16- 4 00:17:35:INFO:root:Setup layers...\n",
      "16- 4 00:17:36:DEBUG:root:InnerProductLayer(h1): sharing weights and bias\n",
      "16- 4 00:17:36:DEBUG:root:InnerProductLayer(h2): sharing weights and bias\n",
      "16- 4 00:17:36:DEBUG:root:InnerProductLayer(y): sharing weights and bias\n",
      "16- 4 00:17:36:INFO:root:Network constructed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Array{Mocha.CoffeeBreak,1}:\n",
       " Mocha.CoffeeBreak(Mocha.TrainingSummary(Any[:iter,:obj_val]),1000,0)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       " Mocha.CoffeeBreak(Mocha.ValidationPerformance(************************************************************\n",
       "          NAME: MNIST-test\n",
       "       BACKEND: Mocha.CPUBackend\n",
       "  ARCHITECTURE: 5 layers\n",
       "............................................................\n",
       " *** Mocha.HDF5DataLayer(test-data)\n",
       "    Outputs ---------------------------\n",
       "          data: Blob(28 x 28 x 1 x 100)\n",
       "         label: Blob(1 x 100)\n",
       "............................................................\n",
       " *** Mocha.InnerProductLayer(h1)\n",
       "    Inputs ----------------------------\n",
       "          data: Blob(28 x 28 x 1 x 100)\n",
       "    Outputs ---------------------------\n",
       "            h1: Blob(128 x 100)\n",
       "............................................................\n",
       " *** Mocha.InnerProductLayer(h2)\n",
       "    Inputs ----------------------------\n",
       "            h1: Blob(128 x 100)\n",
       "    Outputs ---------------------------\n",
       "            h2: Blob(64 x 100)\n",
       "............................................................\n",
       " *** Mocha.InnerProductLayer(y)\n",
       "    Inputs ----------------------------\n",
       "            h2: Blob(64 x 100)\n",
       "    Outputs ---------------------------\n",
       "             y: Blob(10 x 100)\n",
       "............................................................\n",
       " *** Mocha.AccuracyLayer(test-accuracy)\n",
       "    Inputs ----------------------------\n",
       "             y: Blob(10 x 100)\n",
       "         label: Blob(1 x 100)\n",
       "************************************************************\n",
       ",Function[]),1000,0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show performance on test data every 1000 iterations\n",
    "data_layer_test = HDF5DataLayer(name=\"test-data\", source=\"test.txt\", batch_size=100)\n",
    "acc_layer = AccuracyLayer(name=\"test-accuracy\", bottoms=[:y, :label])\n",
    "test_net = Net(\"MNIST-test\", backend, [data_layer_test, common_layers..., acc_layer])\n",
    "add_coffee_break(solver, ValidationPerformance(test_net), every_n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16- 4 00:17:38:DEBUG:root:#DEBUG Checking network topology for back-propagation\n",
      "16- 4 00:17:38:DEBUG:root:Init network MNIST-train\n",
      "16- 4 00:17:39:DEBUG:root:Init parameter weight for layer h1\n",
      "16- 4 00:17:39:DEBUG:root:Init parameter bias for layer h1\n",
      "16- 4 00:17:39:DEBUG:root:Init parameter weight for layer h2\n",
      "16- 4 00:17:39:DEBUG:root:Init parameter bias for layer h2\n",
      "16- 4 00:17:39:DEBUG:root:Init parameter weight for layer y\n",
      "16- 4 00:17:39:DEBUG:root:Init parameter bias for layer y\n",
      "16- 4 00:17:40:DEBUG:root:#DEBUG Initializing coffee breaks\n",
      "16- 4 00:17:40:DEBUG:root:Init network MNIST-test\n",
      "16- 4 00:17:41:INFO:root: TRAIN iter=000000 obj_val=2.32515907\n",
      "16- 4 00:17:41:INFO:root:\n",
      "16- 4 00:17:41:INFO:root:## Performance on Validation Set after 0 iterations\n",
      "16- 4 00:17:41:INFO:root:---------------------------------------------------------\n",
      "16- 4 00:17:41:INFO:root:  Accuracy (avg over 10000) = 8.9000%\n",
      "16- 4 00:17:41:INFO:root:---------------------------------------------------------\n",
      "16- 4 00:17:41:INFO:root:\n",
      "16- 4 00:17:41:DEBUG:root:#DEBUG Entering solver loop\n",
      "16- 4 00:17:43:INFO:root: TRAIN iter=001000 obj_val=0.11005754\n",
      "16- 4 00:17:43:INFO:root:\n",
      "16- 4 00:17:43:INFO:root:## Performance on Validation Set after 1000 iterations\n",
      "16- 4 00:17:43:INFO:root:---------------------------------------------------------\n",
      "16- 4 00:17:43:INFO:root:  Accuracy (avg over 10000) = 94.4600%\n",
      "16- 4 00:17:43:INFO:root:---------------------------------------------------------\n",
      "16- 4 00:17:43:INFO:root:\n",
      "16- 4 00:17:45:INFO:root: TRAIN iter=002000 obj_val=0.10670074\n",
      "16- 4 00:17:45:INFO:root:\n",
      "16- 4 00:17:45:INFO:root:## Performance on Validation Set after 2000 iterations\n",
      "16- 4 00:17:45:INFO:root:---------------------------------------------------------\n",
      "16- 4 00:17:45:INFO:root:  Accuracy (avg over 10000) = 95.7400%\n",
      "16- 4 00:17:45:INFO:root:---------------------------------------------------------\n",
      "16- 4 00:17:45:INFO:root:\n",
      "16- 4 00:17:47:INFO:root: TRAIN iter=003000 obj_val=0.20291162\n",
      "16- 4 00:17:47:INFO:root:\n",
      "16- 4 00:17:47:INFO:root:## Performance on Validation Set after 3000 iterations\n",
      "16- 4 00:17:47:INFO:root:---------------------------------------------------------\n",
      "16- 4 00:17:47:INFO:root:  Accuracy (avg over 10000) = 96.4800%\n",
      "16- 4 00:17:47:INFO:root:---------------------------------------------------------\n",
      "16- 4 00:17:47:INFO:root:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Void,1},1}:\n",
       " [nothing,nothing]\n",
       " [nothing,nothing]\n",
       " [nothing,nothing]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve(solver, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16- 4 00:17:54:DEBUG:root:Destroying network MNIST-train\n",
      "16- 4 00:17:54:INFO:root:AsyncHDF5DataLayer: Stopping IO task...\n",
      "16- 4 00:17:54:INFO:root:AsyncHDF5DataLayer: IO Task reaching the end...\n",
      "16- 4 00:17:54:DEBUG:root:Destroying network MNIST-test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{AbstractString,Array{Mocha.AbstractParameter,1}} with 0 entries"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destroy(net)\n",
    "destroy(test_net)\n",
    "shutdown(backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MXNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Julia, Python, R, Go, JavaScript などに対応した DeepLearning フレームワーク。\n",
    "+ 記述の簡潔さと、（それに伴う）「効率」と「柔軟性」の両立。\n",
    "+ 処理のコア部分は C(C++) で記述されている（それにより軽量性と多言語対応を実現している）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### MXNet のインストール"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（Julia コンソールから↓）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pkg.add(\"MXNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "※ ダイナミックリンクライブラリ libmxnet.so のビルドまでやってくれる。  \n",
    "※ OpenCV の利用、CUDNN 等の利用に際しては、別途それらを有効にして libmxnet.so をビルドし、それを利用するよう `MXNet.jl` を再セットアップする必要あり。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using MXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MXNet.mx.SymbolicNode(MXNet.mx.MX_SymbolHandle(Ptr{Void} @0x00007fceadb1d9c0))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3LP ネットワーク構築\n",
    "mlp = @mx.chain mx.Variable(:data)             =>\n",
    "  mx.FullyConnected(name=:fc1, num_hidden=128) =>\n",
    "  mx.Activation(name=:relu1, act_type=:relu)   =>\n",
    "  mx.FullyConnected(name=:fc2, num_hidden=64)  =>\n",
    "  mx.Activation(name=:relu2, act_type=:relu)   =>\n",
    "  mx.FullyConnected(name=:fc3, num_hidden=10)  =>\n",
    "  mx.SoftmaxOutput(name=:softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MXNet.mx.MXDataProvider(MXNet.mx.MX_DataIterHandle(Ptr{Void} @0x00007fceadb664a0),Tuple{Symbol,Tuple}[(:data,(784,100))],Tuple{Symbol,Tuple}[(:softmax_label,(100,))],100,true,true)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データ取得（データプロバイダ生成）\n",
    "batch_size = 100\n",
    "# include(Pkg.dir(\"MXNet\", \"examples\", \"mnist\", \"mnist-data.jl\"))\n",
    "# train_provider, eval_provider = get_mnist_providers(batch_size)\n",
    "data_name = :data\n",
    "label_name = :softmax_label\n",
    "flat=true\n",
    "train_provider = mx.MNISTProvider(image=\"MNIST_data/train-images-idx3-ubyte\",\n",
    "                                  label=\"MNIST_data/train-labels-idx1-ubyte\",\n",
    "                                  data_name=data_name, label_name=label_name,\n",
    "                                  batch_size=batch_size, shuffle=true, flat=flat, silent=true)\n",
    "eval_provider = mx.MNISTProvider(image=\"MNIST_data/t10k-images-idx3-ubyte\",\n",
    "                                 label=\"MNIST_data/t10k-labels-idx1-ubyte\",\n",
    "                                 data_name=data_name, label_name=label_name,\n",
    "                                 batch_size=batch_size, shuffle=false, flat=flat, silent=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16- 4 00:18:17:INFO:root:Start training on [CPU0]\n",
      "16- 4 00:18:17:INFO:root:Initializing parameters...\n",
      "16- 4 00:18:18:INFO:root:Creating KVStore...\n",
      "16- 4 00:18:18:INFO:root:Start training...\n",
      "16- 4 00:18:19:INFO:root:== Epoch 001 ==========\n",
      "16- 4 00:18:19:INFO:root:## Training summary\n",
      "16- 4 00:18:19:INFO:root:          accuracy = 0.7548\n",
      "16- 4 00:18:19:INFO:root:              time = 1.3291 seconds\n",
      "16- 4 00:18:19:INFO:root:## Validation summary\n",
      "16- 4 00:18:19:INFO:root:          accuracy = 0.9498\n",
      "16- 4 00:18:20:INFO:root:== Epoch 002 ==========\n",
      "16- 4 00:18:20:INFO:root:## Training summary\n",
      "16- 4 00:18:20:INFO:root:          accuracy = 0.9575\n",
      "16- 4 00:18:20:INFO:root:              time = 0.9406 seconds\n",
      "16- 4 00:18:20:INFO:root:## Validation summary\n",
      "16- 4 00:18:20:INFO:root:          accuracy = 0.9678\n",
      "16- 4 00:18:21:INFO:root:== Epoch 003 ==========\n",
      "16- 4 00:18:21:INFO:root:## Training summary\n",
      "16- 4 00:18:21:INFO:root:          accuracy = 0.9700\n",
      "16- 4 00:18:21:INFO:root:              time = 0.8987 seconds\n",
      "16- 4 00:18:21:INFO:root:## Validation summary\n",
      "16- 4 00:18:21:INFO:root:          accuracy = 0.9689\n",
      "16- 4 00:18:22:INFO:root:== Epoch 004 ==========\n",
      "16- 4 00:18:22:INFO:root:## Training summary\n",
      "16- 4 00:18:22:INFO:root:          accuracy = 0.9760\n",
      "16- 4 00:18:22:INFO:root:              time = 0.9881 seconds\n",
      "16- 4 00:18:23:INFO:root:## Validation summary\n",
      "16- 4 00:18:23:INFO:root:          accuracy = 0.9694\n"
     ]
    }
   ],
   "source": [
    "# モデル構築・最適化\n",
    "\n",
    "# モデル setup\n",
    "model = mx.FeedForward(mlp, context=mx.cpu())\n",
    "\n",
    "# optimization algorithm\n",
    "optimizer = mx.SGD(lr=0.1, momentum=0.9)\n",
    "\n",
    "# fit parameters\n",
    "mx.fit(model, optimizer, train_provider, n_epoch=4, eval_data=eval_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10x10000 Array{Float32,2}:\n",
       " 1.86025e-9   4.02211e-9   1.15507e-5  …  9.35833e-7   2.54459e-7 \n",
       " 3.69469e-7   3.88762e-8   0.954931       2.50692e-8   3.24207e-11\n",
       " 1.16894e-6   0.999966     0.00123508     4.8395e-8    1.07991e-8 \n",
       " 2.57024e-5   3.30698e-5   7.87967e-5     6.13717e-7   3.44376e-10\n",
       " 8.22568e-10  7.09632e-11  0.0044216      1.03419e-9   2.8778e-8  \n",
       " 2.04646e-8   2.97188e-9   2.18991e-5  …  0.999847     2.60934e-6 \n",
       " 5.3756e-11   1.45219e-9   2.17161e-5     4.03898e-5   0.999997   \n",
       " 0.999967     5.11702e-7   0.0283429      2.44429e-8   2.21268e-13\n",
       " 7.42553e-8   1.45197e-7   0.00969576     0.000110407  6.22504e-9 \n",
       " 5.96944e-6   1.04052e-13  0.00123922     1.27594e-7   2.23525e-11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 予測\n",
    "probs = mx.predict(model, eval_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on eval set: 96.94%\n"
     ]
    }
   ],
   "source": [
    "# 予測精度確認\n",
    "\n",
    "# collect all labels from eval data\n",
    "labels = Array[]\n",
    "for batch in eval_provider\n",
    "    push!(labels, copy(mx.get(eval_provider, batch, :softmax_label)))\n",
    "end\n",
    "labels = cat(1, labels...)\n",
    "\n",
    "# Now we use compute the accuracy\n",
    "correct = 0\n",
    "for i = 1:length(labels)\n",
    "    # labels are 0...9\n",
    "    if indmax(probs[:,i]) == labels[i]+1\n",
    "        correct += 1\n",
    "    end\n",
    "end\n",
    "accuracy = 100correct/length(labels)\n",
    "println(mx.format(\"Accuracy on eval set: {1:.2f}%\", accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PyCall + TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `PyCall` を利用すれば、Python にインストールした機械学習パッケージ等も利用可能（記述に独特のクセあり）。\n",
    "+ 例として、`TensorFlow` を利用してみる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### インストールと準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使用したいパッケージをインストールした Python の環境を環境変数に設定（pyenv や virtualenv で環境を分けている場合）\n",
    "ENV[\"PYTHON\"] = \"/path/to/user_home/.pyenv/versions/2.7.11/envs/TensorFlow/bin/python\"\n",
    "\n",
    "# PyCall 本体のインストール\n",
    "Pkg.add(\"PyCall\")\n",
    "\n",
    "# インストール済なら、依存ファイルを削除した上で再構築↓\n",
    "# rm(Pkg.dir(\"PyCall\",\"deps\",\"PYTHON\"))\n",
    "# Pkg.build(\"PyCall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using PyCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@pyimport tensorflow as tf\n",
    "# ↑Python の import 文と同様の書き方ができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject <tensorflow.examples.tutorials.mnist.input_data.DataSets object at 0x34e566150>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データ取得\n",
    "@pyimport tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Python で言う `from A.B import C` ということをしたい場合は、`@pyimport A.B.C as C` としなければならない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <tensorflow.python.framework.ops.Tensor object at 0x34e594510>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [nothing, 784])\n",
    "d = tf.placeholder(tf.float32, [nothing, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <tensorflow.python.framework.ops.Tensor object at 0x31282e050>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3LP 構築\n",
    "W1 = tf.Variable(tf.random_normal(Int32[784, 128], mean=0.0, stddev=0.05))\n",
    "b1 = tf.Variable(tf.zeros(Int32[128]))\n",
    "W2 = tf.Variable(tf.random_normal(Int32[128, 64], mean=0.0, stddev=0.05))\n",
    "b2 = tf.Variable(tf.zeros(Int32[64]))\n",
    "W3 = tf.Variable(tf.random_normal(Int32[64, 10], mean=0.0, stddev=0.05))\n",
    "b3 = tf.Variable(tf.zeros(Int32[10]))\n",
    "\n",
    "h1 = tf.nn[:relu](tf.add(tf.matmul(x,  W1), b1))\n",
    "h2 = tf.nn[:relu](tf.add(tf.matmul(h1, W2), b2))\n",
    "y  = tf.nn[:softmax](tf.add(tf.matmul(h2, W3), b3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <tensorflow.python.framework.ops.Tensor object at 0x31283a690>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross_entropy = tf.neg(tf.reduce_sum(tf.mul(d, tf.log(y))))\n",
    "cross_entropy = tf.neg(tf.reduce_sum(tf.mul(d, tf.log(tf.maximum(y, 1e-10)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <tensorflow.python.framework.ops.Operation object at 0x34a932410>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimizer = tf.train[:GradientDescentOptimizer](0.01)\n",
    "optimizer = tf.train[:MomentumOptimizer](0.001, 0.9)\n",
    "train_step = optimizer[:minimize](cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <tensorflow.python.framework.ops.Operation object at 0x34a8fb3d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <tensorflow.python.framework.ops.Tensor object at 0x34ef45550>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(d,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 4\n",
      "I tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 4\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess[:run](tf_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  step, accurary =    500:  0.930\n",
      "  step, accurary =   1000:  0.990\n",
      "  step, accurary =   1500:  0.990\n",
      "  step, accurary =   2000:  1.000\n",
      "accuracy:0.9718999862670898\n"
     ]
    }
   ],
   "source": [
    "for i in 1:2000\n",
    "    batch_xs, batch_ys = mnist[:train][:next_batch](100)\n",
    "    sess[:run](train_step, feed_dict=Dict(x => batch_xs, d => batch_ys))\n",
    "    if i % 500 == 0\n",
    "        train_accuracy = sess[:run](accuracy, feed_dict=Dict(x => batch_xs, d => batch_ys))\n",
    "        @printf(\"  step, accurary = %6d: %6.3f\\n\", i, train_accuracy)\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"accuracy:$(sess[:run](accuracy, feed_dict=Dict(x => mnist[:test][:images], d => mnist[:test][:labels])))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 参考"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ [The Julia Language](http://julialang.org/)（本家サイト、英語）\n",
    "+ [Mocha](https://github.com/pluskid/Mocha.jl)\n",
    "+ [MXNet](https://github.com/dmlc/MXNet.jl)\n",
    "+ [PyCall](https://github.com/stevengj/PyCall.jl)\n",
    "+ [Julia - josephmisiti/awesome-machine-learning](https://github.com/josephmisiti/awesome-machine-learning#julia-general-purpose)（Julia の機械学習関連ライブラリのリンクまとめ。英語）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "ご清聴ありがとうございます。"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 0.4.5",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
