{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Julia の紹介2<br><small>Julia で Deep Learning</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;font-size:150%;line-height:150%\">2016/04/16 機械学習 名古屋 第3回勉強会<br>後藤 俊介 ( @antimon2 )</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 自己紹介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 名前：後藤 俊介\n",
    "+ 所属コミュニティ：**機械学習名古屋**（主催者の1人）、Python東海、Ruby東海\n",
    "+ 言語：**Julia**, Python, Ruby, JavaScript, …\n",
    "+ twitter: [@antimon2](https://twitter.com/antimon2 \"あんちもん2(@antimon2)さん | Twitter\")\n",
    "+ Facebook: [antimon2](https://www.facebook.com/antimon2 \"後藤 俊介\")\n",
    "+ GitHub: [antimon2](https://github.com/antimon2/ \"antimon2 (GOTOH Shunsuke)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "↑今日もこの **Julia** の話。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Julia とは？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "※ 前回発表資料の流用（コピペ＋一部修正）です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [The Julia Language](http://julialang.org/)\n",
    "- 2015/10/04 に [v0.4.0 がリリース](http://julialang.org/blog/2015/10/julia-0.4-release/)（2016/04/16 現在の最新は v0.4.5）\n",
    "- Python/Ruby/R 等の「いいとこどり」言語（詳細後述）\n",
    "- 動作が速い！（LLVM JIT コンパイル）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Julia の特長"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> + Rのように中身がぐちゃぐちゃでなく、\n",
    "+ Rubyのように遅くなく、\n",
    "+ Lispのように原始的またはエレファントでなく、\n",
    "+ Prologのように変態的なところはなく、\n",
    "+ Javaのように硬すぎることはなく、\n",
    "+ Haskellのように抽象的すぎない\n",
    "> \n",
    "> ほどよい言語である\n",
    "\n",
    "引用：http://www.slideshare.net/Nikoriks/julia-28059489"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Julia の目指すもの：\n",
    "\n",
    "+ C のように高速だけど、  \n",
    "  Ruby のような動的型付言語である\n",
    "+ Lisp のように同じ文法で書けるマクロがあって、しかも  \n",
    "  Matlab のような直感的な数式表現もできる\n",
    "+ Python のように総合的なプログラミングができて、  \n",
    "  R のように統計処理も得意で、  \n",
    "  Perl のように文字列処理もできて、  \n",
    "  Matlab のように線形代数もできて、  \n",
    "  shell のように複数のプログラムを組み合わせることもできる\n",
    "+ 超初心者にも習得は簡単で、  \n",
    "  超上級者の満足にも応えられる\n",
    "+ インタラクティブにも動作して、コンパイルもできる\n",
    "\n",
    "（[Why We Created Julia](http://julialang.org/blog/2012/02/why-we-created-julia/) から抜粋・私訳）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep Learning への適用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia の Deep Learning 用パッケージの紹介。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "※ この記事は Julia v0.4.5 を基準としています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ [Mocha](https://github.com/pluskid/Mocha.jl)（C++ 用の [Caffe](http://caffe.berkeleyvision.org/) にインスパイアされて生まれたフレームワーク。互換性・可搬性・速度がウリ）\n",
    "+ [MXNet](https://github.com/dmlc/MXNet.jl)（2015/10 に出たばかりの新しいフレームワーク。軽量・効率性・柔軟性がウリ）\n",
    "+ [PyCall](https://github.com/stevengj/PyCall.jl)（Julia から Python を呼び出すパッケージ。Python にインストール済の機械学習パッケージ（例：TensorFlow）を利用可能）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mocha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ すべて Julia で書かれた DeepLearning フレームワーク。\n",
    "+ 考え方、記述方法等、色々 Caffe から引き継いでいる。\n",
    "+ 扱えるデータ形式等、他のフレームワークとの互換性も持っている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Mocha のインストール"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（Julia コンソールから↓）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pkg.add(\"Mocha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "※ `Blosc`, `HDF5`, `JLD` 等いくつかの依存パッケージも同時に追加される。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Mocha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "《※ Mocha を利用した、今回の 3LP サンプルの構築と学習・結果表示予定地》"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MXNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Julia, Python, R, Go, JavaScript などに対応した DeepLearning フレームワーク。\n",
    "+ 記述の簡潔さと、（それに伴う）「効率」と「柔軟性」の両立。\n",
    "+ 処理のコア部分は C(C++) で記述されている（それにより軽量性と多言語対応を実現している）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### MXNet のインストール"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（Julia コンソールから↓）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pkg.add(\"MXNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "※ ダイナミックリンクライブラリ libmxnet.so のビルドまでやってくれる。  \n",
    "※ OpenCV の利用、CUDNN 等の利用に際しては、別途それらを有効にして libmxnet.so をビルドし、それを利用するよう `MXNet.jl` を再セットアップする必要あり。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using MXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MXNet.mx.SymbolicNode(MXNet.mx.MX_SymbolHandle(Ptr{Void} @0x00007fca8b195490))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3LP ネットワーク構築\n",
    "mlp = @mx.chain mx.Variable(:data)             =>\n",
    "  mx.FullyConnected(name=:fc1, num_hidden=128) =>\n",
    "  mx.Activation(name=:relu1, act_type=:relu)   =>\n",
    "  mx.FullyConnected(name=:fc2, num_hidden=64)  =>\n",
    "  mx.Activation(name=:relu2, act_type=:relu)   =>\n",
    "  mx.FullyConnected(name=:fc3, num_hidden=10)  =>\n",
    "  mx.SoftmaxOutput(name=:softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MXNet.mx.MXDataProvider(MXNet.mx.MX_DataIterHandle(Ptr{Void} @0x00007fca8b27b160),Tuple{Symbol,Tuple}[(:data,(784,100))],Tuple{Symbol,Tuple}[(:softmax_label,(100,))],100,true,true),MXNet.mx.MXDataProvider(MXNet.mx.MX_DataIterHandle(Ptr{Void} @0x00007fca8b3851e0),Tuple{Symbol,Tuple}[(:data,(784,100))],Tuple{Symbol,Tuple}[(:softmax_label,(100,))],100,true,true))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データ取得（データプロバイダ生成）\n",
    "batch_size = 100\n",
    "include(Pkg.dir(\"MXNet\", \"examples\", \"mnist\", \"mnist-data.jl\"))\n",
    "train_provider, eval_provider = get_mnist_providers(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Start training on [CPU0]\n",
      "INFO: Initializing parameters...\n",
      "INFO: Creating KVStore...\n",
      "INFO: Start training...\n",
      "INFO: == Epoch 001 ==========\n",
      "INFO: ## Training summary\n",
      "INFO:           accuracy = 0.7548\n",
      "INFO:               time = 1.2777 seconds\n",
      "INFO: ## Validation summary\n",
      "INFO:           accuracy = 0.9498\n",
      "INFO: == Epoch 002 ==========\n",
      "INFO: ## Training summary\n",
      "INFO:           accuracy = 0.9575\n",
      "INFO:               time = 0.8909 seconds\n",
      "INFO: ## Validation summary\n",
      "INFO:           accuracy = 0.9678\n",
      "INFO: == Epoch 003 ==========\n",
      "INFO: ## Training summary\n",
      "INFO:           accuracy = 0.9700\n",
      "INFO:               time = 0.9023 seconds\n",
      "INFO: ## Validation summary\n",
      "INFO:           accuracy = 0.9689\n",
      "INFO: == Epoch 004 ==========\n",
      "INFO: ## Training summary\n",
      "INFO:           accuracy = 0.9760\n",
      "INFO:               time = 0.8999 seconds\n",
      "INFO: ## Validation summary\n",
      "INFO:           accuracy = 0.9694\n",
      "INFO: == Epoch 005 ==========\n",
      "INFO: ## Training summary\n",
      "INFO:           accuracy = 0.9811\n",
      "INFO:               time = 0.9133 seconds\n",
      "INFO: ## Validation summary\n",
      "INFO:           accuracy = 0.9750\n",
      "INFO: == Epoch 006 ==========\n",
      "INFO: ## Training summary\n",
      "INFO:           accuracy = 0.9840\n",
      "INFO:               time = 0.8973 seconds\n",
      "INFO: ## Validation summary\n",
      "INFO:           accuracy = 0.9721\n",
      "INFO: == Epoch 007 ==========\n",
      "INFO: ## Training summary\n",
      "INFO:           accuracy = 0.9854\n",
      "INFO:               time = 0.9144 seconds\n",
      "INFO: ## Validation summary\n",
      "INFO:           accuracy = 0.9757\n",
      "INFO: == Epoch 008 ==========\n",
      "INFO: ## Training summary\n",
      "INFO:           accuracy = 0.9862\n",
      "INFO:               time = 0.8967 seconds\n",
      "INFO: ## Validation summary\n",
      "INFO:           accuracy = 0.9716\n",
      "INFO: == Epoch 009 ==========\n",
      "INFO: ## Training summary\n",
      "INFO:           accuracy = 0.9879\n",
      "INFO:               time = 0.9243 seconds\n",
      "INFO: ## Validation summary\n",
      "INFO:           accuracy = 0.9761\n",
      "INFO: == Epoch 010 ==========\n",
      "INFO: ## Training summary\n",
      "INFO:           accuracy = 0.9884\n",
      "INFO:               time = 0.9131 seconds\n",
      "INFO: ## Validation summary\n",
      "INFO:           accuracy = 0.9726\n",
      "INFO: == Epoch 011 ==========\n",
      "INFO: ## Training summary\n",
      "INFO:           accuracy = 0.9890\n",
      "INFO:               time = 0.9517 seconds\n",
      "INFO: ## Validation summary\n",
      "INFO:           accuracy = 0.9755\n",
      "INFO: == Epoch 012 ==========\n",
      "INFO: ## Training summary\n",
      "INFO:           accuracy = 0.9895\n",
      "INFO:               time = 0.9116 seconds\n",
      "INFO: ## Validation summary\n",
      "INFO:           accuracy = 0.9791\n",
      "INFO: == Epoch 013 ==========\n",
      "INFO: ## Training summary\n",
      "INFO:           accuracy = 0.9901\n",
      "INFO:               time = 0.9552 seconds\n",
      "INFO: ## Validation summary\n",
      "INFO:           accuracy = 0.9772\n",
      "INFO: == Epoch 014 ==========\n",
      "INFO: ## Training summary\n",
      "INFO:           accuracy = 0.9917\n",
      "INFO:               time = 0.9267 seconds\n",
      "INFO: ## Validation summary\n",
      "INFO:           accuracy = 0.9772\n",
      "INFO: == Epoch 015 ==========\n",
      "INFO: ## Training summary\n",
      "INFO:           accuracy = 0.9910\n",
      "INFO:               time = 0.9100 seconds\n",
      "INFO: ## Validation summary\n",
      "INFO:           accuracy = 0.9772\n",
      "INFO: == Epoch 016 ==========\n",
      "INFO: ## Training summary\n",
      "INFO:           accuracy = 0.9925\n",
      "INFO:               time = 0.9603 seconds\n",
      "INFO: ## Validation summary\n",
      "INFO:           accuracy = 0.9774\n",
      "INFO: == Epoch 017 ==========\n",
      "INFO: ## Training summary\n",
      "INFO:           accuracy = 0.9929\n",
      "INFO:               time = 0.9285 seconds\n",
      "INFO: ## Validation summary\n",
      "INFO:           accuracy = 0.9762\n",
      "INFO: == Epoch 018 ==========\n",
      "INFO: ## Training summary\n",
      "INFO:           accuracy = 0.9925\n",
      "INFO:               time = 0.9775 seconds\n",
      "INFO: ## Validation summary\n",
      "INFO:           accuracy = 0.9800\n",
      "INFO: == Epoch 019 ==========\n",
      "INFO: ## Training summary\n",
      "INFO:           accuracy = 0.9940\n",
      "INFO:               time = 0.9304 seconds\n",
      "INFO: ## Validation summary\n",
      "INFO:           accuracy = 0.9804\n",
      "INFO: == Epoch 020 ==========\n",
      "INFO: ## Training summary\n",
      "INFO:           accuracy = 0.9940\n",
      "INFO:               time = 1.2567 seconds\n",
      "INFO: ## Validation summary\n",
      "INFO:           accuracy = 0.9799\n"
     ]
    }
   ],
   "source": [
    "# モデル構築・最適化\n",
    "\n",
    "# モデル setup\n",
    "model = mx.FeedForward(mlp, context=mx.cpu())\n",
    "\n",
    "# optimization algorithm\n",
    "optimizer = mx.SGD(lr=0.1, momentum=0.9)\n",
    "\n",
    "# fit parameters\n",
    "mx.fit(model, optimizer, train_provider, n_epoch=20, eval_data=eval_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10x10000 Array{Float32,2}:\n",
       " 1.06312e-10  5.80024e-13  2.965e-8     …  4.77526e-11  6.73342e-13\n",
       " 7.46479e-8   1.50914e-11  0.999939        3.83869e-11  9.10979e-16\n",
       " 5.39378e-9   1.0          2.33463e-5      2.85017e-13  2.81719e-13\n",
       " 4.7356e-7    4.01732e-8   8.18917e-10     5.87185e-10  3.66529e-16\n",
       " 8.03094e-10  2.75113e-16  3.04848e-6      3.1257e-14   2.58185e-13\n",
       " 2.61006e-9   8.06292e-16  5.892e-9     …  0.999999     1.2713e-11 \n",
       " 3.00019e-11  6.33867e-15  1.13649e-7      1.09904e-9   1.0        \n",
       " 0.999999     6.59821e-11  3.33885e-5      2.07988e-12  6.45652e-19\n",
       " 2.26256e-9   1.24287e-11  1.17842e-6      1.22676e-6   5.31528e-13\n",
       " 1.94323e-7   3.90443e-21  7.36552e-9      7.82996e-11  1.12308e-19"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 予測\n",
    "probs = mx.predict(model, eval_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on eval set: 97.99%\n"
     ]
    }
   ],
   "source": [
    "# 予測精度確認\n",
    "\n",
    "# collect all labels from eval data\n",
    "labels = Array[]\n",
    "for batch in eval_provider\n",
    "    push!(labels, copy(mx.get(eval_provider, batch, :softmax_label)))\n",
    "end\n",
    "labels = cat(1, labels...)\n",
    "\n",
    "# Now we use compute the accuracy\n",
    "correct = 0\n",
    "for i = 1:length(labels)\n",
    "    # labels are 0...9\n",
    "    if indmax(probs[:,i]) == labels[i]+1\n",
    "        correct += 1\n",
    "    end\n",
    "end\n",
    "accuracy = 100correct/length(labels)\n",
    "println(mx.format(\"Accuracy on eval set: {1:.2f}%\", accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PyCall + TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `PyCall` を利用すれば、Python にインストールした機械学習パッケージ等も利用可能（記述に独特のクセあり）。\n",
    "+ 例として、`TensorFlow` を利用してみる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### インストールと準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使用したいパッケージをインストールした Python の環境を環境変数に設定（pyenv や virtualenv で環境を分けている場合）\n",
    "ENV[\"PYTHON\"] = \"/path/to/user_home/.pyenv/versions/2.7.11/envs/TensorFlow/bin/python\"\n",
    "\n",
    "# PyCall 本体のインストール\n",
    "Pkg.add(\"PyCall\")\n",
    "\n",
    "# インストール済なら、依存ファイルを削除した上で再構築↓\n",
    "# rm(Pkg.dir(\"PyCall\",\"deps\",\"PYTHON\"))\n",
    "# Pkg.build(\"PyCall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using PyCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@pyimport tensorflow as tf\n",
    "# ↑Python の import 文と同様の書き方ができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject <tensorflow.examples.tutorials.mnist.input_data.DataSets object at 0x347d7d150>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データ取得\n",
    "@pyimport tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "mnist = input_data.read_data_sets(\"../MNIST_data/\", one_hot=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Python で言う `from A.B import C` ということをしたい場合は、`@pyimport A.B.C as C` としなければならない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <tensorflow.python.framework.ops.Tensor object at 0x347dab550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [nothing, 784])\n",
    "y_ = tf.placeholder(tf.float32, [nothing, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <tensorflow.python.framework.ops.Tensor object at 0x348010050>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3LP 構築\n",
    "W1 = tf.Variable(tf.random_normal(Int32[784, 128], mean=0.0, stddev=0.05))\n",
    "b1 = tf.Variable(tf.zeros(Int32[128]))\n",
    "W2 = tf.Variable(tf.random_normal(Int32[128, 64], mean=0.0, stddev=0.05))\n",
    "b2 = tf.Variable(tf.zeros(Int32[64]))\n",
    "W3 = tf.Variable(tf.random_normal(Int32[64, 10], mean=0.0, stddev=0.05))\n",
    "b3 = tf.Variable(tf.zeros(Int32[10]))\n",
    "\n",
    "h1 = tf.nn[:relu](tf.add(tf.matmul(x,  W1), b1))\n",
    "h2 = tf.nn[:relu](tf.add(tf.matmul(h1, W2), b2))\n",
    "y  = tf.nn[:softmax](tf.add(tf.matmul(h2, W3), b3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <tensorflow.python.framework.ops.Tensor object at 0x34801e250>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy = tf.neg(tf.reduce_sum(tf.mul(y_, tf.log(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <tensorflow.python.framework.ops.Operation object at 0x348097390>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.train[:GradientDescentOptimizer](0.01)\n",
    "train_step = optimizer[:minimize](cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <tensorflow.python.framework.ops.Operation object at 0x348097490>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <tensorflow.python.framework.ops.Tensor object at 0x3480c0f90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9495999813079834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 4\n",
      "I tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 4\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess[:run](tf_init)\n",
    "\n",
    "for i in 1:2000\n",
    "    batch_xs, batch_ys = mnist[:train][:next_batch](100)\n",
    "    sess[:run](train_step, feed_dict=Dict(x => batch_xs, y_ => batch_ys))\n",
    "end\n",
    "\n",
    "println(\"accuracy:$(sess[:run](accuracy, feed_dict=Dict(x => mnist[:test][:images], y_ => mnist[:test][:labels])))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 参考"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ [The Julia Language](http://julialang.org/)（本家サイト、英語）\n",
    "+ [Mocha](https://github.com/pluskid/Mocha.jl)\n",
    "+ [MXNet](https://github.com/dmlc/MXNet.jl)\n",
    "+ [PyCall](https://github.com/stevengj/PyCall.jl)\n",
    "+ [Julia - josephmisiti/awesome-machine-learning](https://github.com/josephmisiti/awesome-machine-learning#julia-general-purpose)（Julia の機械学習関連ライブラリのリンクまとめ。英語）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "ご清聴ありがとうございます。"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 0.4.5",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
